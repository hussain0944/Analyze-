"""
Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© ÙˆØ§Ù„ØµÙˆØ± Ø§Ù„ØªÙ‚Ù†ÙŠØ©
ÙŠØªØ¶Ù…Ù†: ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±ØŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ù„ØªÙˆØµÙŠØ§Øª
"""

import json
import asyncio
from datetime import datetime
import base64
import io
from typing import Dict, List, Optional, Tuple
import requests
from PIL import Image
import numpy as np
import cv2
from utils import send_to_telegram
import os

class ImageAnalysisSystem:
    def __init__(self):
        self.bot_token = os.getenv("BOT_TOKEN")
        self.analysis_patterns = self.load_analysis_patterns()
        
    def load_analysis_patterns(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ù„ØµÙˆØ±"""
        return {
            # Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
            "trend_patterns": {
                "ascending_triangle": {
                    "name": "Ù…Ø«Ù„Ø« ØµØ§Ø¹Ø¯",
                    "signal": "Ø´Ø±Ø§Ø¡",
                    "confidence_base": 80,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠ ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"
                },
                "descending_triangle": {
                    "name": "Ù…Ø«Ù„Ø« Ù‡Ø§Ø¨Ø·", 
                    "signal": "Ø¨ÙŠØ¹",
                    "confidence_base": 80,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠ Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ"
                },
                "head_and_shoulders": {
                    "name": "Ø±Ø£Ø³ ÙˆÙƒØªÙÙŠÙ†",
                    "signal": "Ø¨ÙŠØ¹",
                    "confidence_base": 85,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ Ù‡Ø§Ø¨Ø· Ù…ÙˆØ«ÙˆÙ‚"
                },
                "inverse_head_shoulders": {
                    "name": "Ø±Ø£Ø³ ÙˆÙƒØªÙÙŠÙ† Ù…Ù‚Ù„ÙˆØ¨",
                    "signal": "Ø´Ø±Ø§Ø¡", 
                    "confidence_base": 85,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ ØµØ§Ø¹Ø¯ Ù…ÙˆØ«ÙˆÙ‚"
                },
                "double_top": {
                    "name": "Ù‚Ù…Ø© Ù…Ø²Ø¯ÙˆØ¬Ø©",
                    "signal": "Ø¨ÙŠØ¹",
                    "confidence_base": 75,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ Ù‡Ø§Ø¨Ø·"
                },
                "double_bottom": {
                    "name": "Ù‚Ø§Ø¹ Ù…Ø²Ø¯ÙˆØ¬",
                    "signal": "Ø´Ø±Ø§Ø¡",
                    "confidence_base": 75,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ ØµØ§Ø¹Ø¯"
                }
            },
            
            # Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
            "support_resistance": {
                "strong_support": {
                    "name": "Ø¯Ø¹Ù… Ù‚ÙˆÙŠ",
                    "signal": "Ø´Ø±Ø§Ø¡",
                    "confidence_base": 70,
                    "description": "Ù…Ø³ØªÙˆÙ‰ Ø¯Ø¹Ù… Ù‚ÙˆÙŠ Ù…Ø®ØªØ¨Ø± Ø¹Ø¯Ø© Ù…Ø±Ø§Øª"
                },
                "strong_resistance": {
                    "name": "Ù…Ù‚Ø§ÙˆÙ…Ø© Ù‚ÙˆÙŠØ©",
                    "signal": "Ø¨ÙŠØ¹", 
                    "confidence_base": 70,
                    "description": "Ù…Ø³ØªÙˆÙ‰ Ù…Ù‚Ø§ÙˆÙ…Ø© Ù‚ÙˆÙŠ Ù…Ø®ØªØ¨Ø± Ø¹Ø¯Ø© Ù…Ø±Ø§Øª"
                },
                "breakout_support": {
                    "name": "ÙƒØ³Ø± Ø§Ù„Ø¯Ø¹Ù…",
                    "signal": "Ø¨ÙŠØ¹",
                    "confidence_base": 85,
                    "description": "ÙƒØ³Ø± Ù…Ø³ØªÙˆÙ‰ Ø¯Ø¹Ù… Ù…Ù‡Ù…"
                },
                "breakout_resistance": {
                    "name": "ÙƒØ³Ø± Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©", 
                    "signal": "Ø´Ø±Ø§Ø¡",
                    "confidence_base": 85,
                    "description": "ÙƒØ³Ø± Ù…Ø³ØªÙˆÙ‰ Ù…Ù‚Ø§ÙˆÙ…Ø© Ù…Ù‡Ù…"
                }
            },
            
            # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ù…ÙˆØ¹
            "candlestick_patterns": {
                "doji": {
                    "name": "Ø¯ÙˆØ¬ÙŠ",
                    "signal": "Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„",
                    "confidence_base": 60,
                    "description": "ØªØ±Ø¯Ø¯ ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚"
                },
                "hammer": {
                    "name": "Ù…Ø·Ø±Ù‚Ø©",
                    "signal": "Ø´Ø±Ø§Ø¡",
                    "confidence_base": 70,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ ØµØ§Ø¹Ø¯"
                },
                "shooting_star": {
                    "name": "Ù†Ø¬Ù…Ø© Ø§Ù„Ø±Ù…Ø§ÙŠØ©",
                    "signal": "Ø¨ÙŠØ¹",
                    "confidence_base": 70,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ Ù‡Ø§Ø¨Ø·"
                },
                "engulfing_bullish": {
                    "name": "Ø§Ø¨ØªÙ„Ø§Ø¹ ØµØ§Ø¹Ø¯",
                    "signal": "Ø´Ø±Ø§Ø¡",
                    "confidence_base": 80,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"
                },
                "engulfing_bearish": {
                    "name": "Ø§Ø¨ØªÙ„Ø§Ø¹ Ù‡Ø§Ø¨Ø·", 
                    "signal": "Ø¨ÙŠØ¹",
                    "confidence_base": 80,
                    "description": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø¹ÙƒØ§Ø³ÙŠ Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ"
                }
            }
        }
    
    async def analyze_chart_image(self, image_data: bytes, user_id: int, chat_type: str = "private") -> str:
        """ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ"""
        try:
            print(f"ğŸ–¼ï¸ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}")
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØµÙˆØ±Ø©
            image = Image.open(io.BytesIO(image_data))
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
            analysis_results = await self._process_chart_image(image)
            
            if not analysis_results:
                return "âŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ ÙˆØ§Ø¶Ø­ Ù„Ù„Ø£Ø³Ø¹Ø§Ø±."
            
            # Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            recommendation = self._generate_image_recommendation(analysis_results)
            
            # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            message = await self._format_image_analysis_message(analysis_results, recommendation)
            
            print(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}")
            return message
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨ØµÙˆØ±Ø© Ø£ÙˆØ¶Ø­."
    
    async def _process_chart_image(self, image: Image) -> Optional[Dict]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
            img_array = np.array(image)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            if len(img_array.shape) == 3:
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                gray = img_array
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø·ÙˆØ· ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
            lines_analysis = self._detect_trend_lines(gray)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            patterns_analysis = self._detect_chart_patterns(gray)
            
            # ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
            levels_analysis = self._detect_support_resistance_levels(gray)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©)
            indicators_analysis = self._detect_indicators(gray)
            
            # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
            combined_analysis = {
                "trends": lines_analysis,
                "patterns": patterns_analysis,
                "levels": levels_analysis,
                "indicators": indicators_analysis,
                "image_quality": self._assess_image_quality(gray),
                "analysis_timestamp": datetime.now()
            }
            
            return combined_analysis
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return None
    
    def _detect_trend_lines(self, gray_image: np.ndarray) -> Dict:
        """ÙƒØ´Ù Ø®Ø·ÙˆØ· Ø§Ù„Ø§ØªØ¬Ø§Ù‡"""
        try:
            # ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
            edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)
            
            # ÙƒØ´Ù Ø§Ù„Ø®Ø·ÙˆØ·
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)
            
            if lines is None:
                return {"trend": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯", "strength": 0, "lines_count": 0}
            
            # ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø®Ø·ÙˆØ·
            ascending_lines = 0
            descending_lines = 0
            horizontal_lines = 0
            
            for line in lines:
                x1, y1, x2, y2 = line[0]
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠÙ„
                if x2 - x1 != 0:
                    slope = (y2 - y1) / (x2 - x1)
                    
                    if slope > 0.1:
                        ascending_lines += 1
                    elif slope < -0.1:
                        descending_lines += 1
                    else:
                        horizontal_lines += 1
            
            total_lines = len(lines)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØºØ§Ù„Ø¨
            if ascending_lines > descending_lines and ascending_lines > horizontal_lines:
                trend = "ØµØ§Ø¹Ø¯"
                strength = min(90, 50 + (ascending_lines / total_lines) * 40)
            elif descending_lines > ascending_lines and descending_lines > horizontal_lines:
                trend = "Ù‡Ø§Ø¨Ø·"
                strength = min(90, 50 + (descending_lines / total_lines) * 40)
            else:
                trend = "Ø¹Ø±Ø¶ÙŠ"
                strength = min(70, 40 + (horizontal_lines / total_lines) * 30)
            
            return {
                "trend": trend,
                "strength": round(strength),
                "lines_count": total_lines,
                "ascending_lines": ascending_lines,
                "descending_lines": descending_lines,
                "horizontal_lines": horizontal_lines
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ø®Ø·ÙˆØ· Ø§Ù„Ø§ØªØ¬Ø§Ù‡: {e}")
            return {"trend": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯", "strength": 0, "lines_count": 0}
    
    def _detect_chart_patterns(self, gray_image: np.ndarray) -> Dict:
        """ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙÙ†ÙŠØ©"""
        try:
            # ØªØ·Ø¨ÙŠÙ‚ ØªÙ†Ø¹ÙŠÙ… Ù„Ù„ØµÙˆØ±Ø©
            blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)
            
            # ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
            edges = cv2.Canny(blurred, 30, 100)
            
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            detected_patterns = []
            
            for contour in contours:
                # ØªØ¨Ø³ÙŠØ· Ø§Ù„ÙƒÙ†ØªÙˆØ±
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                # ØªØ­Ù„ÙŠÙ„ Ø´ÙƒÙ„ Ø§Ù„ÙƒÙ†ØªÙˆØ±
                if len(approx) == 3:
                    # Ù…Ø«Ù„Ø« Ù…Ø­ØªÙ…Ù„
                    pattern = self._analyze_triangle_pattern(contour, approx)
                    if pattern:
                        detected_patterns.append(pattern)
                
                elif len(approx) == 4:
                    # Ù…Ø³ØªØ·ÙŠÙ„ Ø£Ùˆ Ù…ØªÙˆØ§Ø²ÙŠ Ø£Ø¶Ù„Ø§Ø¹
                    pattern = self._analyze_rectangle_pattern(contour, approx)
                    if pattern:
                        detected_patterns.append(pattern)
                
                # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹
                pattern = self._analyze_complex_pattern(contour)
                if pattern:
                    detected_patterns.append(pattern)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø­Ø³Ø¨ Ø§Ù„Ù‚ÙˆØ©
            detected_patterns.sort(key=lambda x: x.get('confidence', 0), reverse=True)
            
            return {
                "patterns_found": len(detected_patterns),
                "patterns": detected_patterns[:5],  # Ø£ÙØ¶Ù„ 5 Ø£Ù†Ù…Ø§Ø·
                "primary_pattern": detected_patterns[0] if detected_patterns else None
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {e}")
            return {"patterns_found": 0, "patterns": [], "primary_pattern": None}
    
    def _analyze_triangle_pattern(self, contour: np.ndarray, approx: np.ndarray) -> Optional[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø«Ù„Ø«ÙŠØ©"""
        try:
            # Ø­Ø³Ø§Ø¨ Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ù…Ø«Ù„Ø«
            points = approx.reshape(-1, 2)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§Ø­Ø© ÙˆØ§Ù„Ù…Ø­ÙŠØ·
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)
            
            if area < 1000 or perimeter < 100:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„ØµØºÙŠØ±Ø©
                return None
            
            # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø«Ù„Ø«
            # Ù‡Ø°Ø§ ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø³Ø· - ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡ Ø£ÙƒØ«Ø±
            pattern_type = "Ù…Ø«Ù„Ø« Ù…ØªÙ…Ø§Ø«Ù„"
            confidence = 60
            signal = "Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ÙƒØ³Ø±"
            
            return {
                "type": "triangle",
                "name": pattern_type,
                "confidence": confidence,
                "signal": signal,
                "area": area,
                "perimeter": perimeter,
                "points": points.tolist()
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø«Ù„Ø«: {e}")
            return None
    
    def _analyze_rectangle_pattern(self, contour: np.ndarray, approx: np.ndarray) -> Optional[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„Ø©"""
        try:
            # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹Ø±Ø¶ Ù„Ù„Ø§Ø±ØªÙØ§Ø¹
            rect = cv2.boundingRect(contour)
            x, y, w, h = rect
            
            aspect_ratio = w / h if h != 0 else 0
            area = cv2.contourArea(contour)
            
            if area < 1000:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„ØµØºÙŠØ±Ø©
                return None
            
            # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            if 0.8 <= aspect_ratio <= 1.2:
                pattern_type = "Ù…Ø±Ø¨Ø¹/Ø¯Ù…Ø¬"
                signal = "Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ÙƒØ³Ø±"
                confidence = 65
            elif aspect_ratio > 2:
                pattern_type = "Ù…Ø³ØªØ·ÙŠÙ„ Ø£ÙÙ‚ÙŠ"
                signal = "Ù†Ø·Ø§Ù‚ ØªØ¯Ø§ÙˆÙ„"
                confidence = 70
            else:
                pattern_type = "Ù…Ø³ØªØ·ÙŠÙ„ Ø¹Ù…ÙˆØ¯ÙŠ"
                signal = "Ù†Ø·Ø§Ù‚ ØªØ¯Ø§ÙˆÙ„"
                confidence = 60
            
            return {
                "type": "rectangle",
                "name": pattern_type,
                "confidence": confidence,
                "signal": signal,
                "aspect_ratio": round(aspect_ratio, 2),
                "area": area,
                "dimensions": {"width": w, "height": h}
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„: {e}")
            return None
    
    def _analyze_complex_pattern(self, contour: np.ndarray) -> Optional[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©"""
        try:
            # Ø­Ø³Ø§Ø¨ Ù…Ø­ÙŠØ· ÙˆÙ…Ø³Ø§Ø­Ø© Ø§Ù„ÙƒÙ†ØªÙˆØ±
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)
            
            if area < 500 or perimeter < 50:
                return None
            
            # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠØ©
            circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter > 0 else 0
            
            # ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´ÙƒÙ„
            if circularity > 0.7:
                return {
                    "type": "curve",
                    "name": "Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø­Ù†ÙŠ",
                    "confidence": 50,
                    "signal": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                    "circularity": round(circularity, 2)
                }
            
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ù‡Ù†Ø§
            return None
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¹Ù‚Ø¯: {e}")
            return None
    
    def _detect_support_resistance_levels(self, gray_image: np.ndarray) -> Dict:
        """ÙƒØ´Ù Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©"""
        try:
            # ØªØ·Ø¨ÙŠÙ‚ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ÙƒØ´Ù Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£ÙÙ‚ÙŠØ©
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
            detect_horizontal = cv2.morphologyEx(gray_image, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)
            
            # ÙƒØ´Ù Ø§Ù„Ø®Ø·ÙˆØ·
            lines = cv2.HoughLinesP(detect_horizontal, 1, np.pi/180, threshold=50, minLineLength=30, maxLineGap=5)
            
            levels = []
            if lines is not None:
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    
                    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø®Ø· Ø£ÙÙ‚ÙŠ
                    if abs(y2 - y1) < 5:  # ØªØ³Ø§Ù…Ø­ Ù„Ù„Ø®Ø·ÙˆØ· Ø´Ø¨Ù‡ Ø§Ù„Ø£ÙÙ‚ÙŠØ©
                        level_y = (y1 + y2) / 2
                        length = abs(x2 - x1)
                        
                        levels.append({
                            "y_position": level_y,
                            "length": length,
                            "strength": min(100, length / 5)  # Ù‚ÙˆØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„
                        })
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù‚ÙˆØ©
            levels.sort(key=lambda x: x['strength'], reverse=True)
            
            # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
            strong_levels = [l for l in levels if l['strength'] > 50]
            
            return {
                "total_levels": len(levels),
                "strong_levels": len(strong_levels),
                "levels": levels[:10],  # Ø£Ù‚ÙˆÙ‰ 10 Ù…Ø³ØªÙˆÙŠØ§Øª
                "analysis": "Ù‚ÙˆÙŠ" if len(strong_levels) > 3 else "Ù…ØªÙˆØ³Ø·" if len(strong_levels) > 1 else "Ø¶Ø¹ÙŠÙ"
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©: {e}")
            return {"total_levels": 0, "strong_levels": 0, "levels": [], "analysis": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"}
    
    def _detect_indicators(self, gray_image: np.ndarray) -> Dict:
        """ÙƒØ´Ù Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            # ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø³Ø· Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            # ÙŠØ¨Ø­Ø« Ø¹Ù† Ø®Ø·ÙˆØ· Ù…Ù†Ø­Ù†ÙŠØ© Ù‚Ø¯ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª
            
            # ØªØ·Ø¨ÙŠÙ‚ ØªÙ†Ø¹ÙŠÙ…
            blurred = cv2.GaussianBlur(gray_image, (3, 3), 0)
            
            # ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
            edges = cv2.Canny(blurred, 50, 150)
            
            # Ø­Ø³Ø§Ø¨ ÙƒØ«Ø§ÙØ© Ø§Ù„Ø®Ø·ÙˆØ·
            line_density = np.sum(edges > 0) / edges.size
            
            indicators_detected = []
            
            # ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒØ«Ø§ÙØ© Ø§Ù„Ø®Ø·ÙˆØ·
            if line_density > 0.05:
                indicators_detected.append({
                    "type": "moving_average",
                    "name": "Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ Ù…Ø­ØªÙ…Ù„",
                    "confidence": 60
                })
            
            if line_density > 0.08:
                indicators_detected.append({
                    "type": "oscillator",
                    "name": "Ù…Ø°Ø¨Ø°Ø¨ Ù…Ø­ØªÙ…Ù„",
                    "confidence": 55
                })
            
            return {
                "indicators_count": len(indicators_detected),
                "indicators": indicators_detected,
                "line_density": round(line_density, 4)
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {e}")
            return {"indicators_count": 0, "indicators": [], "line_density": 0}
    
    def _assess_image_quality(self, gray_image: np.ndarray) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
            variance = cv2.Laplacian(gray_image, cv2.CV_64F).var()
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø·ÙˆØ¹ Ø§Ù„Ù…ØªÙˆØ³Ø·
            brightness = np.mean(gray_image)
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©
            if variance > 500 and 50 <= brightness <= 200:
                quality = "Ù…Ù…ØªØ§Ø²Ø©"
                score = 90
            elif variance > 200 and 30 <= brightness <= 220:
                quality = "Ø¬ÙŠØ¯Ø©"
                score = 70
            elif variance > 100:
                quality = "Ù…ØªÙˆØ³Ø·Ø©"
                score = 50
            else:
                quality = "Ø¶Ø¹ÙŠÙØ©"
                score = 30
            
            return {
                "quality": quality,
                "score": score,
                "variance": round(variance, 2),
                "brightness": round(brightness, 2)
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return {"quality": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯", "score": 0, "variance": 0, "brightness": 0}
    
    def _generate_image_recommendation(self, analysis_results: Dict) -> Dict:
        """Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        try:
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            trends = analysis_results.get('trends', {})
            patterns = analysis_results.get('patterns', {})
            levels = analysis_results.get('levels', {})
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            total_score = 0
            signals = []
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§ØªØ¬Ø§Ù‡
            trend = trends.get('trend', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            trend_strength = trends.get('strength', 0)
            
            if trend == 'ØµØ§Ø¹Ø¯' and trend_strength > 60:
                total_score += 30
                signals.append('Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ')
            elif trend == 'Ù‡Ø§Ø¨Ø·' and trend_strength > 60:
                total_score += 30
                signals.append('Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ')
            elif trend == 'Ø¹Ø±Ø¶ÙŠ':
                total_score += 15
                signals.append('Ø­Ø±ÙƒØ© Ø¹Ø±Ø¶ÙŠØ©')
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            primary_pattern = patterns.get('primary_pattern')
            if primary_pattern:
                pattern_confidence = primary_pattern.get('confidence', 0)
                total_score += pattern_confidence * 0.4
                signals.append(f"Ù†Ù…ÙˆØ°Ø¬: {primary_pattern.get('name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
            
            # ØªÙ‚ÙŠÙŠÙ… Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
            levels_analysis = levels.get('analysis', 'Ø¶Ø¹ÙŠÙ')
            if levels_analysis == 'Ù‚ÙˆÙŠ':
                total_score += 20
                signals.append('Ù…Ø³ØªÙˆÙŠØ§Øª Ø¯Ø¹Ù…/Ù…Ù‚Ø§ÙˆÙ…Ø© Ù‚ÙˆÙŠØ©')
            elif levels_analysis == 'Ù…ØªÙˆØ³Ø·':
                total_score += 10
                signals.append('Ù…Ø³ØªÙˆÙŠØ§Øª Ø¯Ø¹Ù…/Ù…Ù‚Ø§ÙˆÙ…Ø© Ù…ØªÙˆØ³Ø·Ø©')
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            if total_score >= 80:
                recommendation = 'Ø´Ø±Ø§Ø¡ Ù‚ÙˆÙŠ' if trend == 'ØµØ§Ø¹Ø¯' else 'Ø¨ÙŠØ¹ Ù‚ÙˆÙŠ' if trend == 'Ù‡Ø§Ø¨Ø·' else 'Ù…Ø±Ø§Ù‚Ø¨Ø©'
                confidence = min(95, total_score)
            elif total_score >= 60:
                recommendation = 'Ø´Ø±Ø§Ø¡' if trend == 'ØµØ§Ø¹Ø¯' else 'Ø¨ÙŠØ¹' if trend == 'Ù‡Ø§Ø¨Ø·' else 'Ø§Ù†ØªØ¸Ø§Ø±'
                confidence = min(80, total_score)
            elif total_score >= 40:
                recommendation = 'Ø§Ù†ØªØ¸Ø§Ø±'
                confidence = total_score
            else:
                recommendation = 'ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± ÙƒØ§ÙÙ'
                confidence = total_score
            
            return {
                'recommendation': recommendation,
                'confidence': round(confidence),
                'total_score': round(total_score),
                'signals': signals,
                'trend': trend,
                'trend_strength': trend_strength
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªÙˆØµÙŠØ©: {e}")
            return {
                'recommendation': 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„',
                'confidence': 0,
                'total_score': 0,
                'signals': [],
                'trend': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
                'trend_strength': 0
            }
    
    async def _format_image_analysis_message(self, analysis_results: Dict, recommendation: Dict) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ø±Ø³Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            # Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ù„Ù„ØªÙˆØµÙŠØ§Øª
            rec_emoji = {
                'Ø´Ø±Ø§Ø¡ Ù‚ÙˆÙŠ': 'ğŸŸ¢ğŸš€',
                'Ø´Ø±Ø§Ø¡': 'ğŸŸ¢',
                'Ø¨ÙŠØ¹ Ù‚ÙˆÙŠ': 'ğŸ”´ğŸš€', 
                'Ø¨ÙŠØ¹': 'ğŸ”´',
                'Ø§Ù†ØªØ¸Ø§Ø±': 'ğŸŸ¡',
                'Ù…Ø±Ø§Ù‚Ø¨Ø©': 'ğŸ‘ï¸',
                'ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± ÙƒØ§ÙÙ': 'â“',
                'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„': 'âŒ'
            }
            
            rec_text = recommendation['recommendation']
            emoji = rec_emoji.get(rec_text, 'ğŸ“Š')
            
            message = f"""
ğŸ–¼ï¸ **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ**

{emoji} **Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:** {rec_text}
ğŸ¯ **Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©:** {recommendation['confidence']}%

ğŸ“ˆ **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡:**
â€¢ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…: {recommendation['trend']}
â€¢ Ù‚ÙˆØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡: {recommendation['trend_strength']}%

ğŸ” **Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©:**"""
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            patterns = analysis_results.get('patterns', {})
            if patterns.get('patterns_found', 0) > 0:
                for i, pattern in enumerate(patterns.get('patterns', [])[:3]):
                    pattern_emoji = "ğŸ“ˆ" if pattern.get('signal') == 'Ø´Ø±Ø§Ø¡' else "ğŸ“‰" if pattern.get('signal') == 'Ø¨ÙŠØ¹' else "âšª"
                    message += f"\nâ€¢ {pattern_emoji} {pattern.get('name', 'Ù†Ù…ÙˆØ°Ø¬')} ({pattern.get('confidence', 0)}%)"
            else:
                message += "\nâ€¢ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ø¶Ø­Ø©"
            
            # Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
            levels = analysis_results.get('levels', {})
            message += f"""

ğŸ›¡ï¸ **Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª: {levels.get('total_levels', 0)}
â€¢ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù‚ÙˆÙŠØ©: {levels.get('strong_levels', 0)}
â€¢ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {levels.get('analysis', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}"""
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            indicators = analysis_results.get('indicators', {})
            if indicators.get('indicators_count', 0) > 0:
                message += f"\n\nğŸ“Š **Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:**"
                for indicator in indicators.get('indicators', []):
                    message += f"\nâ€¢ {indicator.get('name', 'Ù…Ø¤Ø´Ø±')} ({indicator.get('confidence', 0)}%)"
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
            if recommendation.get('signals'):
                message += f"\n\nğŸ”” **Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:**"
                for signal in recommendation['signals']:
                    message += f"\nâ€¢ {signal}"
            
            # Ø¥Ø¶Ø§ÙØ© ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©
            quality = analysis_results.get('image_quality', {})
            message += f"""

ğŸ“¸ **Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©:** {quality.get('quality', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} ({quality.get('score', 0)}%)

âš ï¸ **Ù…Ù„Ø§Ø­Ø¸Ø©:** Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆÙ‚Ø¯ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ£ÙƒÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

ğŸ• **ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ¤– **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ**
"""
            
            return message
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
            return "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„."

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…
image_analyzer = ImageAnalysisSystem()